// Load environment variables
require('dotenv').config();

const express = require('express');
const cors = require('cors');
const multer = require('multer');
const path = require('path');
const fs = require('fs');
const crypto = require('crypto');

const app = express();
const PORT = process.env.PORT || 3000;

// Middleware
app.use(cors());
app.use(express.json({ limit: '50mb' }));

// Configure multer for file uploads
const storage = multer.memoryStorage();
const upload = multer({ 
    storage: storage,
    limits: { fileSize: 10 * 1024 * 1024 } // 10MB limit
});

// API configuration - Load from environment variables
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const OPENAI_API_URL = 'https://api.openai.com/v1/chat/completions';

// Backup API keys for enhanced reliability
const BACKUP_CAPTION_API_KEY = process.env.BACKUP_CAPTION_API_KEY;
const BACKUP_DICTIONARY_API_KEY = process.env.BACKUP_DICTIONARY_API_KEY;

// Unlimited mode configuration
const UNLIMITED_MODE = process.env.UNLIMITED_MODE === 'true' || true; // Default to unlimited

// Aggressive fallback mode - prioritize fallback over API calls
const AGGRESSIVE_FALLBACK = process.env.AGGRESSIVE_FALLBACK === 'true'; // Default to false - use API when available

// Dictionary API configuration (using OpenAI)
const DICTIONARY_API_KEY = process.env.OPENAI_API_KEY;
const DICTIONARY_API_URL = 'https://api.openai.com/v1/chat/completions';

// Usage tracking
let usageStats = {
    totalRequests: 0,
    totalCost: 0,
    requestsByKey: {},
    dailyUsage: {},
    imageHashes: new Map() // For caching
};

// Load usage stats from file if exists
const USAGE_FILE = 'usage-stats.json';
if (fs.existsSync(USAGE_FILE)) {
    try {
        const savedStats = JSON.parse(fs.readFileSync(USAGE_FILE, 'utf8'));
        usageStats = { ...usageStats, ...savedStats };
        // Convert imageHashes back to Map
        if (savedStats.imageHashes) {
            usageStats.imageHashes = new Map(Object.entries(savedStats.imageHashes));
        }
    } catch (error) {
        console.error('Error loading usage stats:', error);
    }
}

// Save usage stats to file
function saveUsageStats() {
    try {
        const statsToSave = {
            ...usageStats,
            imageHashes: Object.fromEntries(usageStats.imageHashes)
        };
        fs.writeFileSync(USAGE_FILE, JSON.stringify(statsToSave, null, 2));
    } catch (error) {
        console.error('Error saving usage stats:', error);
    }
}

// Validate API keys are loaded
if (!OPENAI_API_KEY) {
    console.error('âŒ No valid OpenAI API key found!');
    console.error('Please set OPENAI_API_KEY environment variable or create a .env file');
    console.error('See env.template for example configuration');
}

// Log backup API key status
if (BACKUP_CAPTION_API_KEY) {
    if (isOpenAICompatible(BACKUP_CAPTION_API_KEY)) {
        console.log('âœ… Backup caption API key loaded (OpenAI-compatible)');
    } else {
        console.log('âš ï¸ Backup caption API key loaded (non-OpenAI format - will use primary key)');
    }
} else {
    console.log('âš ï¸ No backup caption API key found');
}

if (BACKUP_DICTIONARY_API_KEY) {
    if (isOpenAICompatible(BACKUP_DICTIONARY_API_KEY)) {
        console.log('âœ… Backup dictionary API key loaded (OpenAI-compatible)');
    } else {
        console.log('âš ï¸ Backup dictionary API key loaded (non-OpenAI format - will use primary key)');
    }
} else {
    console.log('âš ï¸ No backup dictionary API key found');
}

// Function to get current API key
function getCurrentApiKey() {
    return OPENAI_API_KEY;
}

// Function to check if an API key is OpenAI-compatible
function isOpenAICompatible(key) {
    return key && key.startsWith('sk-') && !key.startsWith('sk-or-v1');
}

// Function to get caption API key with backup support
function getCaptionApiKey() {
    // Only use backup key if it's OpenAI-compatible, otherwise use primary key
    if (BACKUP_CAPTION_API_KEY && isOpenAICompatible(BACKUP_CAPTION_API_KEY)) {
        return BACKUP_CAPTION_API_KEY;
    }
    return OPENAI_API_KEY;
}

// Function to get dictionary API key with backup support
function getDictionaryApiKey() {
    // Only use backup key if it's OpenAI-compatible, otherwise use primary key
    if (BACKUP_DICTIONARY_API_KEY && isOpenAICompatible(BACKUP_DICTIONARY_API_KEY)) {
        return BACKUP_DICTIONARY_API_KEY;
    }
    return OPENAI_API_KEY;
}

// Function to make dictionary API request with backup support
async function makeDictionaryRequest(requestBody, maxRetries = 2) {
    let lastError = null;
    
    for (let attempt = 0; attempt < maxRetries; attempt++) {
        try {
            const currentKey = getDictionaryApiKey();
            const isBackupKey = currentKey === BACKUP_DICTIONARY_API_KEY;
            console.log(`ğŸ” Making dictionary API request (attempt ${attempt + 1}/${maxRetries}) using ${isBackupKey ? 'backup' : 'primary'} key...`);
            
            // Add timeout to prevent hanging requests
            const controller = new AbortController();
            const timeoutId = setTimeout(() => controller.abort(), 30000); // 30 second timeout
            
            const response = await fetch(DICTIONARY_API_URL, {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${currentKey}`,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify(requestBody),
                signal: controller.signal
            });
            
            clearTimeout(timeoutId);
            
            if (response.ok) {
                const data = await response.json();
                console.log('âœ… Dictionary API request successful');
                
                // Track usage
                const keyType = isBackupKey ? 'backup_dictionary_key' : 'primary_dictionary_key';
                usageStats.requestsByKey[keyType] = (usageStats.requestsByKey[keyType] || 0) + 1;
                usageStats.totalRequests++;
                
                // Estimate cost
                const estimatedCost = estimateApiCost(requestBody, data);
                usageStats.totalCost += estimatedCost;
                
                // Track daily usage
                const today = new Date().toISOString().split('T')[0];
                if (!usageStats.dailyUsage[today]) {
                    usageStats.dailyUsage[today] = { requests: 0, cost: 0 };
                }
                usageStats.dailyUsage[today].requests++;
                usageStats.dailyUsage[today].cost += estimatedCost;
                
                saveUsageStats();
                
                return data;
            } else {
                const errorText = await response.text();
                console.error(`âŒ Dictionary API Response Error (attempt ${attempt + 1}):`);
                console.error(`   Status: ${response.status} ${response.statusText}`);
                console.error(`   Body: ${errorText}`);
                
                // Check for specific error types
                if (response.status === 401) {
                    lastError = new Error('Invalid API key - please check your dictionary API key');
                } else if (response.status === 429) {
                    lastError = new Error('Rate limit exceeded - please wait before trying again');
                } else if (response.status === 402 || response.status === 403) {
                    lastError = new Error('API limit reached - trying backup key');
                } else {
                    lastError = new Error(`Dictionary API request failed: ${response.status} ${response.statusText} - ${errorText}`);
                }
            }
        } catch (error) {
            console.error(`âŒ Dictionary API Network Error (attempt ${attempt + 1}):`, error);
            lastError = error;
            
            if (attempt < maxRetries - 1) {
                console.log(`Waiting 2 seconds before retry...`);
                await new Promise(resolve => setTimeout(resolve, 2000));
            }
        }
    }
    
    console.error(`Dictionary API request failed after ${maxRetries} attempts. Last error:`, lastError);
    throw lastError || new Error('Dictionary API request failed');
}

// Function to make API request with automatic fallback and backup support
async function makeApiRequestWithFallback(requestBody, maxRetries = 2) {
    let lastError = null;
    
    for (let attempt = 0; attempt < maxRetries; attempt++) {
        try {
            const currentKey = getCaptionApiKey();
            const isBackupKey = currentKey === BACKUP_CAPTION_API_KEY;
            console.log(`ğŸ”‘ Using ${isBackupKey ? 'backup caption' : 'primary'} API key (attempt ${attempt + 1}/${maxRetries})`);
            console.log(`ğŸ”— Connecting to: ${OPENAI_API_URL}`);
            
            // Add timeout to prevent hanging requests
            const controller = new AbortController();
            const timeoutId = setTimeout(() => controller.abort(), 30000); // 30 second timeout
            
            const response = await fetch(OPENAI_API_URL, {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${currentKey}`,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify(requestBody),
                signal: controller.signal
            });
            
            clearTimeout(timeoutId);
            
            console.log(`ğŸ“¡ Response status: ${response.status}`);
            
            if (response.ok) {
                const data = await response.json();
                console.log(`âœ… API request successful`);
                
                // Track usage
                const keyType = isBackupKey ? 'backup_caption_key' : 'primary_caption_key';
                usageStats.requestsByKey[keyType] = (usageStats.requestsByKey[keyType] || 0) + 1;
                usageStats.totalRequests++;
                
                // Estimate cost (rough calculation)
                const estimatedCost = estimateApiCost(requestBody, data);
                usageStats.totalCost += estimatedCost;
                
                // Track daily usage
                const today = new Date().toISOString().split('T')[0];
                if (!usageStats.dailyUsage[today]) {
                    usageStats.dailyUsage[today] = { requests: 0, cost: 0 };
                }
                usageStats.dailyUsage[today].requests++;
                usageStats.dailyUsage[today].cost += estimatedCost;
                
                saveUsageStats();
                
                return data;
            } else {
                const errorText = await response.text();
                console.error(`âŒ API Response Error:`);
                console.error(`   Status: ${response.status} ${response.statusText}`);
                console.error(`   Body: ${errorText}`);
                
                // Check for specific error types
                if (response.status === 401) {
                    console.error(`âŒ Authentication failed - API key may be invalid`);
                    lastError = new Error('Invalid API key - please check your OpenAI API key');
                } else if (response.status === 429) {
                    console.error(`âŒ Rate limit exceeded`);
                    lastError = new Error('Rate limit exceeded - please wait before trying again');
                } else if (response.status === 402) {
                    console.error(`âŒ Insufficient credits or quota exceeded - trying backup key`);
                    lastError = new Error('API quota exceeded - trying backup key');
                } else if (response.status === 403) {
                    console.error(`âŒ Access forbidden - quota may be exceeded - trying backup key`);
                    lastError = new Error('API access issue - trying backup key');
                } else {
                    lastError = new Error(`API request failed: ${response.status} ${response.statusText} - ${errorText}`);
                }
            }
        } catch (error) {
            console.error(`âŒ Network/Connection Error:`, error);
            console.error(`   Error Type: ${error.name}`);
            console.error(`   Error Message: ${error.message}`);
            console.error(`   Error Code: ${error.code}`);
            
            // Enhanced error detection
            if (error.name === 'AbortError') {
                lastError = new Error('Request timeout - API request took too long');
            } else if (error.code === 'ECONNREFUSED') {
                console.error(`âŒ Connection refused - cannot reach OpenAI API`);
                lastError = new Error('Cannot connect to OpenAI API - check your internet connection');
            } else if (error.code === 'ENOTFOUND') {
                console.error(`âŒ DNS lookup failed - cannot resolve api.openai.com`);
                lastError = new Error('Cannot reach OpenAI servers - check your internet connection');
            } else if (error.code === 'ETIMEDOUT') {
                console.error(`âŒ Connection timeout`);
                lastError = new Error('Connection to OpenAI timed out');
            } else if (error.message.includes('fetch')) {
                console.error(`âŒ Fetch failed - likely a network issue`);
                lastError = new Error('Network request failed - check your connection');
            } else {
                lastError = error;
            }
            
            if (attempt < maxRetries - 1) {
                console.log(`Waiting 2 seconds before retry...`);
                await new Promise(resolve => setTimeout(resolve, 2000));
            }
        }
    }
    
    console.error(`API request failed. Last error:`, lastError);
    throw lastError || new Error('API request failed');
}

// Estimate API cost based on request and response
function estimateApiCost(requestBody, response) {
    // Rough cost estimation (adjust based on actual pricing)
    const inputTokens = JSON.stringify(requestBody).length / 4; // Rough token estimation
    const outputTokens = response.choices?.[0]?.message?.content?.length / 4 || 0;
    
    // GPT-4o-mini pricing (approximate)
    const inputCostPer1K = 0.00015;
    const outputCostPer1K = 0.0006;
    
    return (inputTokens / 1000 * inputCostPer1K) + (outputTokens / 1000 * outputCostPer1K);
}

// Generate image hash for caching
function generateImageHash(imageBuffer) {
    return crypto.createHash('sha256').update(imageBuffer).digest('hex');
}

// Check if image is cached
function getCachedResult(imageHash) {
    return usageStats.imageHashes.get(imageHash);
}

// Cache result
function cacheResult(imageHash, result) {
    usageStats.imageHashes.set(imageHash, {
        result: result,
        timestamp: Date.now(),
        accessCount: 1
    });
    saveUsageStats();
}

// Update cache access count
function updateCacheAccess(imageHash) {
    const cached = usageStats.imageHashes.get(imageHash);
    if (cached) {
        cached.accessCount++;
        cached.lastAccessed = Date.now();
        saveUsageStats();
    }
}

// Image analysis validation
function validateImageAnalysis(analysis) {
    const issues = [];
    
    if (!analysis.mainSubject || analysis.mainSubject.length < 2) {
        issues.push('mainSubject is missing or too short');
    }
    
    if (!analysis.category || analysis.category.length < 2) {
        issues.push('category is missing or too short');
    }
    
    if (!analysis.description || analysis.description.length < 10) {
        issues.push('description is missing or too short');
    }
    
    const genericTerms = ['photo', 'image', 'picture', 'something', 'object', 'thing'];
    if (genericTerms.some(term => analysis.mainSubject.toLowerCase().includes(term))) {
        issues.push('mainSubject is too generic');
    }
    
    if (genericTerms.some(term => analysis.description.toLowerCase().includes(term))) {
        issues.push('description is too generic');
    }
    
    if (analysis.confidence === 'low') {
        issues.push('low confidence in analysis');
    }
    
    if (!analysis.keywords || !Array.isArray(analysis.keywords) || analysis.keywords.length === 0) {
        issues.push('AI-generated keywords are missing');
    }
    
    return {
        isValid: issues.length === 0,
        issues: issues
    };
}

// Enhanced caption validation with strict Chinese-only requirements
function validateCaptions(captions, analysis) {
    const validatedCaptions = [];
    
    // Ensure captions is an array
    if (!Array.isArray(captions)) {
        console.warn('Captions is not an array:', captions);
        return [];
    }
    
    for (const caption of captions) {
        // Require chinese and english fields
        if (!caption.chinese || !caption.english) {
            console.warn('Caption missing required fields:', caption);
            continue;
        }
        
        // FLEXIBLE VALIDATION: Allow more natural, personalized Chinese text
        const chineseText = caption.chinese.trim();
        
        // Must contain Chinese characters
        const hasChineseCharacters = /[\u4e00-\u9fff]/.test(chineseText);
        if (!hasChineseCharacters) {
            console.warn('âŒ Caption contains no Chinese characters:', chineseText);
            continue;
        }
        
        // Allow some flexibility - check for excessive English words but allow some mixed content
        const englishWordCount = (chineseText.match(/[a-zA-Z]+/g) || []).length;
        const chineseCharacterCount = (chineseText.match(/[\u4e00-\u9fff]/g) || []).length;
        
        // If there are too many English words relative to Chinese characters, skip
        if (englishWordCount > 2 && englishWordCount > chineseCharacterCount / 3) {
            console.warn('âŒ Caption has too many English words:', chineseText);
            continue;
        }
        
        // Ensure Chinese caption has meaningful content (at least 4 characters)
        if (chineseText.length < 4) {
            console.warn('âŒ Caption too short:', chineseText);
            continue;
        }
        
        // Check for only the most problematic mixed language patterns
        const problematicPatterns = [
            /è¿™æ˜¯\s*[a-zA-Z]/,  // "è¿™æ˜¯a", "è¿™æ˜¯an", "è¿™æ˜¯the", etc.
            /è¿™æ˜¯\s*person/,    // "è¿™æ˜¯person"
            /è¿™æ˜¯\s*thing/,     // "è¿™æ˜¯thing"
            /è¿™æ˜¯\s*object/,    // "è¿™æ˜¯object"
            /è¿™æ˜¯\s*something/, // "è¿™æ˜¯something"
            /è¿™æ˜¯\s*someone/    // "è¿™æ˜¯someone"
        ];
        
        // Only filter out the most problematic patterns
        const hasProblematicPattern = problematicPatterns.some(pattern => pattern.test(chineseText));
        
        if (hasProblematicPattern) {
            console.warn('âŒ Problematic mixed language pattern filtered out:', chineseText);
            continue;
        }
        
        // More flexible sentence validation - allow shorter, more natural expressions
        const hasProperPunctuation = /[ã€‚ï¼ï¼Ÿ]$/.test(chineseText);
        const isLongEnough = chineseText.length >= 4; // More flexible minimum length
        
        // Only warn about very short sentences without punctuation, but don't reject them
        if (!hasProperPunctuation && chineseText.length < 3) {
            console.warn('âš ï¸ Very short sentence without punctuation:', chineseText);
            // Don't continue - allow it through
        }
        
        // Generate pinyin if missing
        if (!caption.pinyin) {
            caption.pinyin = generatePinyinFallback(chineseText);
            console.log('Generated fallback pinyin:', caption.pinyin);
        }
        
        // More flexible relevance filtering - only filter out extremely low relevance
        if (caption.relevance === 'low' && chineseText.length < 3) {
            console.warn('âŒ Extremely low relevance and very short caption filtered out:', chineseText);
            continue;
        }
        
        // Ensure relevance is set
        caption.relevance = caption.relevance || 'medium';
        
        console.log('âœ… Validated caption:', chineseText);
        validatedCaptions.push(caption);
    }
    
    // Return at least one caption if we have any, even if validation is strict
    return validatedCaptions.length > 0 ? validatedCaptions.slice(0, 3) : [];
}

// Enhanced fallback pinyin generation for missing pinyin
function generatePinyinFallback(chineseText) {
    // Expanded character-to-pinyin mapping for common characters
    const pinyinMap = {
        'ä½ ': 'nÇ', 'å¥½': 'hÇo', 'å­¦': 'xuÃ©', 'ä¹ ': 'xÃ­', 'å¤§': 'dÃ ', 'ä¸­': 'zhÅng', 'å›½': 'guÃ³',
        'è€': 'lÇo', 'å¸ˆ': 'shÄ«', 'ç”Ÿ': 'shÄ“ng', 'æœ‹': 'pÃ©ng', 'å‹': 'yÇ’u', 'å®¶': 'jiÄ', 'åº­': 'tÃ­ng',
        'å·¥': 'gÅng', 'ä½œ': 'zuÃ²', 'æ—¶': 'shÃ­', 'é—´': 'jiÄn', 'æˆ‘': 'wÇ’', 'æ˜¯': 'shÃ¬', 'ä¸€': 'yÄ«',
        'ä¸ª': 'gÃ¨', 'çš„': 'de', 'åœ¨': 'zÃ i', 'å¾ˆ': 'hÄ›n', 'æœ‰': 'yÇ’u', 'å’Œ': 'hÃ©', 'äº†': 'le',
        'ä¸': 'bÃ¹', 'è¦': 'yÃ o', 'ä¼š': 'huÃ¬', 'æ¥': 'lÃ¡i', 'åˆ°': 'dÃ o', 'å»': 'qÃ¹', 'ä¸Š': 'shÃ ng',
        'ä¸‹': 'xiÃ ', 'é‡Œ': 'lÇ', 'å¤–': 'wÃ i', 'å‰': 'qiÃ¡n', 'å': 'hÃ²u', 'å·¦': 'zuÇ’', 'å³': 'yÃ²u',
        'çŒ«': 'mÄo', 'ç‹—': 'gÇ’u', 'é¸Ÿ': 'niÇo', 'é±¼': 'yÃº', 'èŠ±': 'huÄ', 'æ ‘': 'shÃ¹', 'å±±': 'shÄn',
        'æ°´': 'shuÇ', 'å¤©': 'tiÄn', 'åœ°': 'dÃ¬', 'äºº': 'rÃ©n', 'æ‰‹': 'shÇ’u', 'çœ¼': 'yÇn', 'å£': 'kÇ’u',
        'å¿ƒ': 'xÄ«n', 'å¤´': 'tÃ³u', 'èº«': 'shÄ“n', 'è„š': 'jiÇo', 'è½¦': 'chÄ“', 'æˆ¿': 'fÃ¡ng', 'é—¨': 'mÃ©n',
        'çª—': 'chuÄng', 'æ¡Œ': 'zhuÅ', 'æ¤…': 'yÇ', 'åºŠ': 'chuÃ¡ng', 'ä¹¦': 'shÅ«', 'ç¬”': 'bÇ', 'çº¸': 'zhÇ',
        'åƒ': 'chÄ«', 'å–': 'hÄ“', 'ç¡': 'shuÃ¬', 'èµ°': 'zÇ’u', 'è·‘': 'pÇo', 'çœ‹': 'kÃ n', 'å¬': 'tÄ«ng',
        'è¯´': 'shuÅ', 'ç¬‘': 'xiÃ o', 'å“­': 'kÅ«', 'çˆ±': 'Ã i', 'æƒ³': 'xiÇng', 'çŸ¥': 'zhÄ«', 'é“': 'dÃ o',
        'è¿™': 'zhÃ¨', 'é‚£': 'nÃ ', 'ä»€': 'shÃ©n', 'ä¹ˆ': 'me', 'æ€': 'zÄ›n', 'æ ·': 'yÃ ng', 'ä¸º': 'wÃ¨i',
        'ä»€': 'shÃ©n', 'ä¹ˆ': 'me', 'å¯': 'kÄ›', 'ä»¥': 'yÇ', 'èƒ½': 'nÃ©ng', 'å¤Ÿ': 'gÃ²u', 'å°±': 'jiÃ¹',
        'éƒ½': 'dÅu', 'è¿˜': 'hÃ¡i', 'ä¹Ÿ': 'yÄ›', 'åª': 'zhÇ', 'è¦': 'yÃ o', 'å¦‚': 'rÃº', 'æœ': 'guÇ’',
        'å› ': 'yÄ«n', 'ä¸º': 'wÃ¨i', 'æ‰€': 'suÇ’', 'ä»¥': 'yÇ', 'ä½†': 'dÃ n', 'æ˜¯': 'shÃ¬', 'å¦‚': 'rÃº',
        'æœ': 'guÇ’', 'è™½': 'suÄ«', 'ç„¶': 'rÃ¡n', 'ä½†': 'dÃ n', 'æ˜¯': 'shÃ¬', 'ä¸': 'bÃ¹', 'è¿‡': 'guÃ²',
        'å›¾': 'tÃº', 'ç‰‡': 'piÃ n', 'ç…§': 'zhÃ o', 'ç›¸': 'xiÃ ng', 'ç¾': 'mÄ›i', 'ä¸½': 'lÃ¬', 'æ¼‚': 'piÃ o',
        'äº®': 'liÃ ng', 'å¥½': 'hÇo', 'çœ‹': 'kÃ n', 'æœ‰': 'yÇ’u', 'è¶£': 'qÃ¹', 'ç‰¹': 'tÃ¨', 'åˆ«': 'biÃ©',
        'é': 'fÄ“i', 'å¸¸': 'chÃ¡ng', 'çœŸ': 'zhÄ“n', 'çš„': 'de', 'ç¡®': 'quÃ¨', 'å®': 'shÃ­', 'ç¡®': 'quÃ¨'
    };
    
    return chineseText.split('').map(char => pinyinMap[char] || char).join(' ');
}

// Comprehensive fallback caption system
function generateFallbackCaptions(imageBuffer, mimeType = 'image/jpeg') {
    console.log('ğŸ”„ Generating fallback captions (API bypass mode)');
    
    // Generate a simple hash to determine caption type
    const hash = crypto.createHash('md5').update(imageBuffer).digest('hex');
    const hashNum = parseInt(hash.substring(0, 8), 16);
    
    // Categorized fallback captions
    const fallbackCaptions = {
        general: [
            {
                chinese: 'è¿™æ˜¯ä¸€å¼ å¾ˆæœ‰è¶£çš„å›¾ç‰‡ã€‚',
                pinyin: 'zhÃ¨ shÃ¬ yÄ« zhÄng hÄ›n yÇ’u qÃ¹ de tÃº piÃ n',
                english: 'This is a very interesting picture.',
                relevance: 'high'
            },
            {
                chinese: 'è¿™å¼ ç…§ç‰‡çœ‹èµ·æ¥å¾ˆç‰¹åˆ«ã€‚',
                pinyin: 'zhÃ¨ zhÄng zhÃ o piÃ n kÃ n qÇ lÃ¡i hÄ›n tÃ¨ biÃ©',
                english: 'This photo looks very special.',
                relevance: 'high'
            },
            {
                chinese: 'æˆ‘å–œæ¬¢è¿™å¼ å›¾ç‰‡çš„å†…å®¹ã€‚',
                pinyin: 'wÇ’ xÇ huÄn zhÃ¨ zhÄng tÃº piÃ n de nÃ¨i rÃ³ng',
                english: 'I like the content of this picture.',
                relevance: 'high'
            }
        ],
        nature: [
            {
                chinese: 'è¿™å¼ è‡ªç„¶é£æ™¯ç…§ç‰‡çœŸç¾ä¸½ã€‚',
                pinyin: 'zhÃ¨ zhÄng zÃ¬ rÃ¡n fÄ“ng jÇng zhÃ o piÃ n zhÄ“n mÄ›i lÃ¬',
                english: 'This natural landscape photo is really beautiful.',
                relevance: 'high'
            },
            {
                chinese: 'å¤§è‡ªç„¶çš„æ™¯è‰²æ€»æ˜¯è®©äººå¿ƒæ—·ç¥æ€¡ã€‚',
                pinyin: 'dÃ  zÃ¬ rÃ¡n de jÇng sÃ¨ zÇ’ng shÃ¬ rÃ ng rÃ©n xÄ«n kuÃ ng shÃ©n yÃ­',
                english: 'Natural scenery always makes people feel relaxed and happy.',
                relevance: 'high'
            },
            {
                chinese: 'è¿™ä¸ªé£æ™¯è®©æˆ‘æƒ³èµ·äº†ç¾å¥½çš„å›å¿†ã€‚',
                pinyin: 'zhÃ¨ gÃ¨ fÄ“ng jÇng rÃ ng wÇ’ xiÇng qÇ le mÄ›i hÇo de huÃ­ yÃ¬',
                english: 'This scenery reminds me of beautiful memories.',
                relevance: 'high'
            }
        ],
        people: [
            {
                chinese: 'è¿™å¼ ç…§ç‰‡ä¸­çš„äººç‰©çœ‹èµ·æ¥å¾ˆå‹å¥½ã€‚',
                pinyin: 'zhÃ¨ zhÄng zhÃ o piÃ n zhÅng de rÃ©n wÃ¹ kÃ n qÇ lÃ¡i hÄ›n yÇ’u hÇo',
                english: 'The people in this photo look very friendly.',
                relevance: 'high'
            },
            {
                chinese: 'ä»–ä»¬çš„ç¬‘å®¹å¾ˆæ¸©æš–ï¼Œè®©äººæ„Ÿåˆ°å¿«ä¹ã€‚',
                pinyin: 'tÄ men de xiÃ o rÃ³ng hÄ›n wÄ“n nuÇn, rÃ ng rÃ©n gÇn dÃ o kuÃ i lÃ¨',
                english: 'Their smiles are warm and make people feel happy.',
                relevance: 'high'
            },
            {
                chinese: 'è¿™å¼ ç…§ç‰‡æ•æ‰åˆ°äº†ç¾å¥½çš„ç¬é—´ã€‚',
                pinyin: 'zhÃ¨ zhÄng zhÃ o piÃ n bÇ” zhuÅ dÃ o le mÄ›i hÇo de shÃ¹n jiÄn',
                english: 'This photo captured a beautiful moment.',
                relevance: 'high'
            }
        ],
        food: [
            {
                chinese: 'è¿™é“èœçœ‹èµ·æ¥éå¸¸ç¾å‘³ã€‚',
                pinyin: 'zhÃ¨ dÃ o cÃ i kÃ n qÇ lÃ¡i fÄ“i chÃ¡ng mÄ›i wÃ¨i',
                english: 'This dish looks very delicious.',
                relevance: 'high'
            },
            {
                chinese: 'é£Ÿç‰©çš„é¢œè‰²å’Œæ‘†ç›˜éƒ½å¾ˆç²¾è‡´ã€‚',
                pinyin: 'shÃ­ wÃ¹ de yÃ¡n sÃ¨ hÃ© bÇi pÃ¡n dÅu hÄ›n jÄ«ng zhÃ¬',
                english: 'The food\'s color and presentation are both exquisite.',
                relevance: 'high'
            },
            {
                chinese: 'è¿™è®©æˆ‘æƒ³èµ·äº†å®¶çš„å‘³é“ã€‚',
                pinyin: 'zhÃ¨ rÃ ng wÇ’ xiÇng qÇ le jiÄ de wÃ¨i dÃ o',
                english: 'This reminds me of the taste of home.',
                relevance: 'high'
            }
        ],
        animals: [
            {
                chinese: 'è¿™åªå°åŠ¨ç‰©çœŸå¯çˆ±ã€‚',
                pinyin: 'zhÃ¨ zhÄ« xiÇo dÃ²ng wÃ¹ zhÄ“n kÄ› Ã i',
                english: 'This little animal is really cute.',
                relevance: 'high'
            },
            {
                chinese: 'å®ƒçš„è¡¨æƒ…å¾ˆæœ‰è¶£ï¼Œè®©äººå¿ä¸ä½æƒ³ç¬‘ã€‚',
                pinyin: 'tÄ de biÇo qÃ­ng hÄ›n yÇ’u qÃ¹, rÃ ng rÃ©n rÄ›n bÃ¹ zhÃ¹ xiÇng xiÃ o',
                english: 'Its expression is very funny and makes people want to laugh.',
                relevance: 'high'
            },
            {
                chinese: 'åŠ¨ç‰©ä»¬çš„çº¯çœŸæ€»æ˜¯èƒ½æ²»æ„ˆäººå¿ƒã€‚',
                pinyin: 'dÃ²ng wÃ¹ men de chÃºn zhÄ“n zÇ’ng shÃ¬ nÃ©ng zhÃ¬ yÃ¹ rÃ©n xÄ«n',
                english: 'The innocence of animals can always heal people\'s hearts.',
                relevance: 'high'
            }
        ],
        objects: [
            {
                chinese: 'è¿™ä¸ªç‰©å“çš„è®¾è®¡å¾ˆæœ‰åˆ›æ„ã€‚',
                pinyin: 'zhÃ¨ gÃ¨ wÃ¹ pÇn de shÃ¨ jÃ¬ hÄ›n yÇ’u chuÃ ng yÃ¬',
                english: 'The design of this object is very creative.',
                relevance: 'high'
            },
            {
                chinese: 'å®ƒçš„å½¢çŠ¶å’Œé¢œè‰²æ­é…å¾—å¾ˆå¥½ã€‚',
                pinyin: 'tÄ de xÃ­ng zhuÃ ng hÃ© yÃ¡n sÃ¨ dÄ pÃ¨i de hÄ›n hÇo',
                english: 'Its shape and color are well matched.',
                relevance: 'high'
            },
            {
                chinese: 'è¿™ä¸ªç‰©å“çœ‹èµ·æ¥å¾ˆå®ç”¨ã€‚',
                pinyin: 'zhÃ¨ gÃ¨ wÃ¹ pÇn kÃ n qÇ lÃ¡i hÄ›n shÃ­ yÃ²ng',
                english: 'This object looks very practical.',
                relevance: 'high'
            }
        ]
    };
    
    // Select category based on hash
    const categories = Object.keys(fallbackCaptions);
    const selectedCategory = categories[hashNum % categories.length];
    const captions = fallbackCaptions[selectedCategory];
    
    console.log(`ğŸ“ Using fallback captions for category: ${selectedCategory}`);
    
    // Return 2-3 captions with some randomization
    const numCaptions = 2 + (hashNum % 2); // 2 or 3 captions
    const selectedCaptions = [];
    
    for (let i = 0; i < numCaptions; i++) {
        const captionIndex = (hashNum + i) % captions.length;
        selectedCaptions.push(captions[captionIndex]);
    }
    
    return selectedCaptions;
}

// Enhanced fallback analysis
function generateFallbackAnalysis() {
    return {
        mainSubject: 'å›¾ç‰‡å†…å®¹',
        category: 'general',
        description: 'è¿™æ˜¯ä¸€å¼ æœ‰è¶£çš„å›¾ç‰‡ï¼Œå†…å®¹ä¸°å¯Œå¤šå½©ã€‚',
        context: 'å›¾ç‰‡å±•ç¤ºäº†ä¸€ä¸ªæœ‰è¶£çš„åœºæ™¯æˆ–ç‰©ä½“ã€‚',
        mood: 'positive',
        colors: 'various colors',
        details: 'å›¾ç‰‡åŒ…å«å¤šç§å…ƒç´ ï¼Œå€¼å¾—ä»”ç»†è§‚å¯Ÿã€‚',
        confidence: 'medium',
        alternativeSubjects: [],
        keywords: ['å›¾ç‰‡', 'æœ‰è¶£', 'å†…å®¹', 'è§‚å¯Ÿ'],
        chineseKeywords: ['å›¾ç‰‡', 'æœ‰è¶£', 'å†…å®¹', 'è§‚å¯Ÿ']
    };
}

// Fix common JSON parsing issues
function fixCommonJsonIssues(jsonText) {
    // Fix common issues that break JSON parsing
    let fixed = jsonText;
    
    // Fix unescaped quotes in strings
    fixed = fixed.replace(/"([^"]*)"([^"]*)"([^"]*)"/g, '"$1\\"$2\\"$3"');
    
    // Fix trailing commas
    fixed = fixed.replace(/,(\s*[}\]])/g, '$1');
    
    // Fix missing quotes around keys
    fixed = fixed.replace(/([{,]\s*)([a-zA-Z_][a-zA-Z0-9_]*)\s*:/g, '$1"$2":');
    
    // Fix single quotes to double quotes
    fixed = fixed.replace(/'/g, '"');
    
    // Fix newlines in strings
    fixed = fixed.replace(/\n/g, '\\n');
    fixed = fixed.replace(/\r/g, '\\r');
    fixed = fixed.replace(/\t/g, '\\t');
    
    return fixed;
}

// Extract captions from malformed response text
function extractCaptionsFromText(text, analysis) {
    const captions = [];
    
    try {
        // Try to find Chinese text patterns
        const chinesePattern = /[\u4e00-\u9fff]+/g;
        const chineseMatches = text.match(chinesePattern);
        
        if (chineseMatches && chineseMatches.length > 0) {
            // Take the first few Chinese sentences
            const chineseTexts = chineseMatches.slice(0, 3);
            
            for (const chinese of chineseTexts) {
                if (chinese.length > 2) { // Only use meaningful Chinese text
                    const caption = {
                        chinese: chinese,
                        pinyin: generatePinyinFallback(chinese),
                        english: `This appears to be about ${analysis.mainSubject || 'the image content'}`,
                        relevance: 'medium',
                        keywordsUsed: analysis.keywords || []
                    };
                    captions.push(caption);
                }
            }
        }
        
        // If no Chinese text found, try to extract from structured text
        if (captions.length === 0) {
            const lines = text.split('\n');
            for (const line of lines) {
                if (line.includes('chinese') || line.includes('Chinese')) {
                    const chineseMatch = line.match(/[\u4e00-\u9fff]+/);
                    if (chineseMatch) {
                        const caption = {
                            chinese: chineseMatch[0],
                            pinyin: generatePinyinFallback(chineseMatch[0]),
                            english: `Description of ${analysis.mainSubject || 'the image'}`,
                            relevance: 'medium',
                            keywordsUsed: analysis.keywords || []
                        };
                        captions.push(caption);
                    }
                }
            }
        }
        
    } catch (error) {
        console.error('Error extracting captions from text:', error);
    }
    
    return captions.slice(0, 3); // Return max 3 captions
}



// Analyze image with caching and comprehensive fallback
async function analyzeImage(imageBuffer, mimeType = 'image/jpeg') {
    try {
        console.log('ğŸ” Analyzing image content...');
        
        // Generate hash for caching
        const imageHash = generateImageHash(imageBuffer);
        
        // Check cache first
        const cached = getCachedResult(imageHash);
        if (cached && (Date.now() - cached.timestamp) < 24 * 60 * 60 * 1000) { // 24 hour cache
            console.log('ğŸ“¦ Using cached analysis result');
            updateCacheAccess(imageHash);
            return cached.result;
        }
        
        // If aggressive fallback is enabled, use fallback system immediately
        if (AGGRESSIVE_FALLBACK) {
            console.log('ğŸ”„ Aggressive fallback mode - using fallback analysis');
            const fallbackAnalysis = generateFallbackAnalysis();
            const fallbackCaptions = generateFallbackCaptions(imageBuffer, mimeType);
            
            const result = {
                analysis: fallbackAnalysis,
                captions: fallbackCaptions
            };
            
            // Cache the fallback result
            cacheResult(imageHash, result);
            return result;
        }
        
        // Convert buffer to base64
        const base64Image = imageBuffer.toString('base64');
        
        const prompt = `You are an expert image analyst and keyword generator. Analyze this image carefully and provide a detailed, accurate description with intelligent keywords.

        IMPORTANT INSTRUCTIONS:
        - Look at the image carefully and describe ONLY what you actually see
        - Be specific about all visible elements: objects, people, animals, food, scenes, artwork, text, etc.
        - Identify the most prominent elements first
        - Consider the context and setting
        - Note colors, lighting, and mood
        - Describe any text you can read
        - Note facial expressions and characteristics when visible
        - Identify specific items, species, or details when possible
        - Describe art styles, visual elements, and composition when applicable
        - Generate relevant keywords that would help create accurate Mandarin captions
        - Be factual and avoid assumptions
        
        CRITICAL: You MUST respond with ONLY valid JSON. Do not include any text before or after the JSON object. Do not use markdown formatting.
        
        Return your analysis in this exact JSON format:
        {
            "mainSubject": "the most prominent object, person, animal, or scene in the image",
            "category": "descriptive category of the main content",
            "description": "detailed, factual description of what is visible in the image",
            "context": "the setting, location, or situation shown",
            "mood": "the feeling or atmosphere conveyed by the image",
            "colors": "dominant colors and color scheme",
            "details": "specific visual details that would help create accurate captions",
            "confidence": "high|medium|low - your confidence in the analysis",
            "alternativeSubjects": ["other notable subjects in the image"],
            "keywords": ["relevant", "keywords", "for", "caption", "generation"],
            "chineseKeywords": ["Ã¤Â¸Â­Ã¦â€“â€¡Ã¥â€¦Â³Ã©"Â®Ã¨Â¯", "for", "better", "captions"]
        }
        
        Be precise and only describe what you can clearly see. Generate keywords that are specific to the image content.`;

        const requestBody = {
            model: 'gpt-4o-mini',
            messages: [
                {
                    role: 'user',
                    content: [
                        {
                            type: 'text',
                            text: prompt
                        },
                        {
                            type: 'image_url',
                            image_url: {
                                url: `data:${mimeType};base64,${base64Image}`
                            }
                        }
                    ]
                }
            ],
            max_tokens: 400,
            temperature: 0.1,
            top_p: 0.9,
            frequency_penalty: 0.1,
            presence_penalty: 0.1
        };

        console.log('ğŸ” Making API request for image analysis...');
        const data = await makeApiRequestWithFallback(requestBody);
        console.log('âœ… API request successful, processing response...');
        const analysisText = data.choices[0].message.content;
        
        let analysis;
        try {
            // Clean the response text before parsing - more robust approach
            let cleanAnalysisText = analysisText.trim();
            
            // Remove any text before the first {
            const jsonStart = cleanAnalysisText.indexOf('{');
            if (jsonStart > 0) {
                cleanAnalysisText = cleanAnalysisText.substring(jsonStart);
            }
            
            // Remove any text after the last }
            const jsonEnd = cleanAnalysisText.lastIndexOf('}');
            if (jsonEnd > 0 && jsonEnd < cleanAnalysisText.length - 1) {
                cleanAnalysisText = cleanAnalysisText.substring(0, jsonEnd + 1);
            }
            
            // Remove markdown code blocks
            cleanAnalysisText = cleanAnalysisText.replace(/```json\s*/g, '').replace(/```\s*/g, '');
            
            // Remove any remaining leading/trailing whitespace
            cleanAnalysisText = cleanAnalysisText.trim();
            
            // Log the raw response for debugging
            console.log('ğŸ” Raw AI analysis response:', cleanAnalysisText);
            
            // Try to parse the JSON
            analysis = JSON.parse(cleanAnalysisText);
            
            // Validate that we have the required fields
            if (!analysis || typeof analysis !== 'object') {
                throw new Error('Invalid analysis object structure');
            }
            
            // Ensure required fields exist with fallbacks
            analysis.mainSubject = analysis.mainSubject || 'unknown subject';
            analysis.category = analysis.category || 'objects';
            analysis.description = analysis.description || 'No description available';
            analysis.context = analysis.context || 'No context available';
            analysis.mood = analysis.mood || 'neutral';
            analysis.colors = analysis.colors || 'various colors';
            analysis.details = analysis.details || 'No specific details';
            analysis.confidence = analysis.confidence || 'medium';
            analysis.alternativeSubjects = analysis.alternativeSubjects || [];
            analysis.keywords = analysis.keywords || [];
            analysis.chineseKeywords = analysis.chineseKeywords || [];
            
            const validationResult = validateImageAnalysis(analysis);
            if (!validationResult.isValid) {
                console.warn('âŒ Analysis validation failed:', validationResult.issues);
                // Don't throw error, just log the issues and continue
            }
            
            console.log('âœ… Successfully analyzed image content:', analysis);
            
            // Cache the result
            cacheResult(imageHash, analysis);
            
            return analysis;
        } catch (parseError) {
            console.error('âŒ Failed to parse AI response as JSON:', parseError);
            console.error('âŒ Raw response text:', analysisText);
            console.error('âŒ Cleaned response text:', cleanAnalysisText);
            
            // If parsing fails, throw an error to encourage retry
            console.error('âŒ Failed to create analysis from AI response');
            throw new Error(`AI analysis failed - response parsing error: ${parseError.message}`);
        }

    } catch (error) {
        console.error('Error analyzing image:', error);
        console.error('Error details:', {
            message: error.message,
            stack: error.stack,
            name: error.name
        });
        
        // Always return fallback captions instead of throwing error
        console.log('ğŸ”„ API failed, using comprehensive fallback system');
        const fallbackAnalysis = generateFallbackAnalysis();
        const fallbackCaptions = generateFallbackCaptions(imageBuffer, mimeType);
        
        const result = {
            analysis: fallbackAnalysis,
            captions: fallbackCaptions,
            fallbackUsed: true,
            error: error.message
        };
        
        // Cache the fallback result
        const imageHash = generateImageHash(imageBuffer);
        cacheResult(imageHash, result);
        
        return result;
    }
}

// Parse natural language response format for captions
function parseNaturalLanguageResponse(responseText, analysis) {
    const captions = [];
    
    try {
        console.log('ğŸ” Parsing natural language response...');
        
        // Try to find numbered items (1., 2., 3.)
        const numberedPattern = /(\d+)\.\s*([\u4e00-\u9fff][^]*?)(?=\d+\.|$)/gs;
        const matches = [...responseText.matchAll(numberedPattern)];
        
        if (matches.length > 0) {
            for (const match of matches) {
                const section = match[2];
                
                // Extract Chinese text
                const chineseMatch = section.match(/([\u4e00-\u9fff][\u4e00-\u9fff\sï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼š""''ï¼ˆï¼‰ã€ã€‘ã€Šã€‹]*[ã€‚ï¼ï¼Ÿ])/);
                if (!chineseMatch) continue;
                
                const chinese = chineseMatch[1].trim();
                
                // Extract pinyin
                const pinyinMatch = section.match(/[Pp]inyin:\s*([^\n]+)/);
                const pinyin = pinyinMatch ? pinyinMatch[1].trim() : generatePinyinFallback(chinese);
                
                // Extract English
                const englishMatch = section.match(/[Ee]nglish:\s*([^\n]+)/);
                const english = englishMatch ? englishMatch[1].trim() : `Description of ${analysis.mainSubject || 'the image'}`;
                
                captions.push({
                    chinese: chinese,
                    pinyin: pinyin,
                    english: english,
                    relevance: 'high',
                    keywordsUsed: analysis.keywords || []
                });
            }
        }
        
        // If no numbered format found, try alternative extraction
        if (captions.length === 0) {
            console.log('ğŸ”„ No numbered format found, trying alternative extraction...');
            
            // Split response into lines and process
            const lines = responseText.split('\n').map(line => line.trim()).filter(line => line.length > 0);
            
            let currentCaption = null;
            
            for (let i = 0; i < lines.length; i++) {
                const line = lines[i];
                
                // Check if this line starts a new caption (numbered or contains Chinese characters)
                if (/^[0-9]+\./.test(line) || /[\u4e00-\u9fff]/.test(line)) {
                    // Save previous caption if exists
                    if (currentCaption && currentCaption.chinese) {
                        captions.push(currentCaption);
                    }
                    
                    // Start new caption
                    currentCaption = {
                        chinese: '',
                        pinyin: '',
                        english: '',
                        relevance: 'high',
                        keywordsUsed: analysis.keywords || []
                    };
                    
                    // Extract Chinese text from the line
                    const chineseMatch = line.match(/[\u4e00-\u9fff][\u4e00-\u9fff\sï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼š""''ï¼ˆï¼‰ã€ã€‘ã€Šã€‹]*/);
                    if (chineseMatch) {
                        currentCaption.chinese = chineseMatch[0].trim();
                    } else {
                        // If no Chinese found, use the whole line after removing numbering
                        currentCaption.chinese = line.replace(/^[0-9]+\.\s*/, '').trim();
                    }
                }
                // Check for pinyin line
                else if (line.toLowerCase().startsWith('pinyin:') || line.toLowerCase().startsWith('æ‹¼éŸ³:')) {
                    if (currentCaption) {
                        currentCaption.pinyin = line.replace(/^(pinyin|æ‹¼éŸ³):\s*/i, '').trim();
                    }
                }
                // Check for English line
                else if (line.toLowerCase().startsWith('english:') || line.toLowerCase().startsWith('è‹±æ–‡:')) {
                    if (currentCaption) {
                        currentCaption.english = line.replace(/^(english|è‹±æ–‡):\s*/i, '').trim();
                    }
                }
                // If we have a current caption and this line contains Chinese characters, it might be additional Chinese text
                else if (currentCaption && /[\u4e00-\u9fff]/.test(line) && !currentCaption.chinese) {
                    currentCaption.chinese = line.trim();
                }
            }
            
            // Don't forget the last caption
            if (currentCaption && currentCaption.chinese) {
                captions.push(currentCaption);
            }
        }
        
        // If still no structured format found, try to extract Chinese sentences directly
        if (captions.length === 0) {
            console.log('ğŸ”„ No structured format found, extracting Chinese sentences directly...');
            const chinesePattern = /[\u4e00-\u9fff][\u4e00-\u9fff\sï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼š""''ï¼ˆï¼‰ã€ã€‘ã€Šã€‘]*[ã€‚ï¼ï¼Ÿ]/g;
            const chineseMatches = responseText.match(chinesePattern);
            
            if (chineseMatches && chineseMatches.length > 0) {
                for (let i = 0; i < Math.min(chineseMatches.length, 3); i++) {
                    const chinese = chineseMatches[i].trim();
                    if (chinese.length > 6) { // Only use meaningful sentences
                        captions.push({
                            chinese: chinese,
                            pinyin: generatePinyinFallback(chinese),
                            english: `Personal observation about ${analysis.mainSubject || 'the image'}`,
                            relevance: 'high',
                            keywordsUsed: analysis.keywords || []
                        });
                    }
                }
            }
        }
        
        // Ensure we have pinyin for all captions
        captions.forEach(caption => {
            if (!caption.pinyin) {
                caption.pinyin = generatePinyinFallback(caption.chinese);
            }
        });
        
        console.log('âœ… Parsed captions from natural language:', captions.length);
        return captions.slice(0, 3); // Return max 3 captions
        
    } catch (error) {
        console.error('âŒ Error parsing natural language response:', error);
        return [];
    }
}

// Generate Chinese descriptions with enhanced retry logic
async function generateChineseDescriptions(analysis, retryCount = 0) {
    const maxRetries = 2;
    
    // If aggressive fallback is enabled, skip API calls and return empty result
    if (AGGRESSIVE_FALLBACK) {
        console.log('ğŸ”„ Aggressive fallback mode enabled - no captions will be generated');
        return [];
    }
    
    try {
        const prompt = `You are an expert native Chinese speaker creating deeply personalized, emotional, and specific captions for this exact image. Your goal is to create captions that sound like a real Chinese person would naturally and personally describe this image, with genuine emotion and specific details.

        DETAILED IMAGE ANALYSIS:
        - Main Subject: ${analysis.mainSubject}
        - Category: ${analysis.category}
        - Description: ${analysis.description}
        - Context: ${analysis.context}
        - Mood: ${analysis.mood}
        ${analysis.colors ? `- Colors: ${analysis.colors}` : ''}
        ${analysis.details ? `- Specific Details: ${analysis.details}` : ''}
        ${analysis.confidence ? `- Analysis Confidence: ${analysis.confidence}` : ''}
        ${analysis.keywords ? `- AI-Generated Keywords: ${analysis.keywords.join(', ')}` : ''}
        ${analysis.chineseKeywords ? `- Chinese Keywords: ${analysis.chineseKeywords.join(', ')}` : ''}
        ${analysis.alternativeSubjects ? `- Alternative Subjects: ${analysis.alternativeSubjects.join(', ')}` : ''}
        
        ABSOLUTE REQUIREMENTS - NO EXCEPTIONS:
        1. Create DEEPLY PERSONALIZED, EMOTIONAL Chinese sentences that capture the ESSENCE and FEELING of this specific image
        2. Each Chinese caption MUST be a complete, natural sentence (10-30 characters minimum) with genuine emotion
        3. Use ONLY Chinese characters (æ±‰å­—) - ZERO English words allowed in Chinese field
        4. Use specific, vivid Chinese vocabulary that captures the unique details and atmosphere of this image
        5. Make sentences sound like a native Chinese speaker personally experiencing and describing this image
        6. Include accurate pinyin with proper tone marks (Ä Ã¡ Ç Ã , Ä“ Ã© Ä› Ã¨, etc.)
        7. Provide clear, accurate English translations that convey the same emotion
        8. Use varied, natural sentence structures with personal perspective
        9. Be highly specific and detailed - capture the unique character of this exact image
        10. Incorporate the analysis keywords naturally into emotionally rich sentences
        11. Each sentence must end with proper Chinese punctuation (ã€‚ï¼ï¼Ÿ)
        12. NEVER use mixed language like "è¿™æ˜¯a person" - translate everything to Chinese
        13. CRITICAL: The Chinese field must contain ONLY Chinese characters - no English, numbers, or symbols
        14. If you cannot create a proper Chinese sentence, do not include that caption
        15. Focus on PERSONAL REACTIONS, EMOTIONS, and SPECIFIC DETAILS that make this image unique
        
        PERSONALIZED, EMOTIONAL SENTENCE PATTERNS FOR DIFFERENT CONTENT TYPES:
        
        For People/Portraits:
        - "è¿™ä½å¥³å£«çš„çº¢è‰²è¿è¡£è£™åœ¨é˜³å…‰ä¸‹é—ªé—ªå‘å…‰ï¼Œå¥¹çš„ç¬‘å®¹æ¸©æš–å¾—è®©äººå¿ƒåŠ¨ã€‚"
        - "è¿™ä¸ªå­©å­çš„ç¬‘å£°å¦‚æ­¤çº¯çœŸï¼Œè®©æˆ‘æƒ³èµ·äº†è‡ªå·±ç¾å¥½çš„ç«¥å¹´æ—¶å…‰ã€‚"
        - "è¿™ä½è€äººä¸“æ³¨è¯»ä¹¦çš„æ ·å­è®©æˆ‘æ„Ÿå—åˆ°äº†å²æœˆé™å¥½çš„ç¾å¥½ã€‚"
        
        For Animals:
        - "è¿™åªæ©˜è‰²å°çŒ«èœ·ç¼©åœ¨é˜³å…‰ä¸‹çš„æ ·å­å¤ªå¯çˆ±äº†ï¼ŒçœŸæƒ³æ‘¸æ‘¸å®ƒæŸ”è½¯çš„æ¯›å‘ã€‚"
        - "çœ‹ç€è¿™åªé‡‘æ¯›çŠ¬åœ¨è‰åœ°ä¸Šè‡ªç”±å¥”è·‘ï¼Œæˆ‘çš„å¿ƒæƒ…ä¹Ÿå˜å¾—è½»æ¾æ„‰å¿«èµ·æ¥ã€‚"
        - "è¿™åªå°é¸Ÿçš„æ­Œå£°å¦‚æ­¤åŠ¨å¬ï¼Œä»¿ä½›åœ¨è¯‰è¯´ç€æ˜¥å¤©çš„ç¾å¥½æ•…äº‹ã€‚"
        
        For Food:
        - "è¿™ç›˜é¥ºå­çš„é¦™å‘³è®©æˆ‘æƒ³èµ·äº†å¦ˆå¦ˆçš„å‘³é“ï¼Œæ¯ä¸€å£éƒ½å……æ»¡äº†å®¶çš„æ¸©æš–ã€‚"
        - "è¿™ç¢—æ‹‰é¢çš„çƒ­æ°”è…¾è…¾ï¼Œçº¢ç»¿ç›¸é—´çš„é…èœè®©äººé£Ÿæ¬²å¤§å¼€ï¼ŒçœŸæƒ³ç«‹åˆ»å“å°ã€‚"
        - "è¿™ä¸ªè›‹ç³•çš„ç²¾è‡´è£…é¥°è®©æˆ‘æ„Ÿå—åˆ°äº†åˆ¶ä½œè€…çš„ç”¨å¿ƒï¼Œæ¯ä¸€å¤„ç»†èŠ‚éƒ½é‚£ä¹ˆå®Œç¾ã€‚"
        
        For Nature/Landscapes:
        - "è¿™ç‰‡æ¹–æ°´çš„å®é™è®©æˆ‘å†…å¿ƒæ„Ÿåˆ°å‰æ‰€æœªæœ‰çš„å¹³é™ï¼Œä»¿ä½›æ—¶é—´éƒ½é™æ­¢äº†ã€‚"
        - "è¿™åº§å±±å³°çš„é›„ä¼Ÿè®©æˆ‘æ„Ÿå—åˆ°äº†å¤§è‡ªç„¶çš„ä¼Ÿå¤§ï¼Œå¿ƒä¸­æ¶Œèµ·æ— é™çš„æ•¬ç•ä¹‹æƒ…ã€‚"
        - "è¿™ç‰‡æ¨±èŠ±çš„ç¾æ™¯è®©æˆ‘é™¶é†‰å…¶ä¸­ï¼Œç²‰è‰²çš„èŠ±ç“£å¦‚é›ªèŠ±èˆ¬é£˜æ´’ï¼Œç¾å¾—è®©äººçª’æ¯ã€‚"
        
        For Objects/Art:
        - "è¿™ä¸ªèŠ±ç“¶ä¸Šçš„å±±æ°´ç”»è®©æˆ‘æ„Ÿå—åˆ°äº†ä¸­å›½ä¼ ç»Ÿæ–‡åŒ–çš„æ·±åšåº•è•´å’Œè‰ºæœ¯é­…åŠ›ã€‚"
        - "è¿™å¹…æŠ½è±¡ç”»çš„è‰²å½©æ­é…å¦‚æ­¤å¤§èƒ†ï¼Œè®©æˆ‘æ„Ÿå—åˆ°äº†è‰ºæœ¯å®¶å†…å¿ƒå¼ºçƒˆçš„æƒ…æ„Ÿè¡¨è¾¾ã€‚"
        - "è¿™è¾†è·‘è½¦çš„æµçº¿å‹è®¾è®¡è®©æˆ‘æ„Ÿå—åˆ°äº†é€Ÿåº¦ä¸æ¿€æƒ…çš„å®Œç¾ç»“åˆï¼Œä»¤äººå¿ƒé©°ç¥å¾€ã€‚"
        
        For Abstract/Patterns:
        - "è¿™ä¸ªå‡ ä½•å›¾æ¡ˆçš„å¯¹ç§°ç¾è®©æˆ‘æ„Ÿå—åˆ°äº†æ•°å­¦ä¸è‰ºæœ¯çš„å®Œç¾èåˆï¼Œä»¤äººå¹ä¸ºè§‚æ­¢ã€‚"
        - "è¿™äº›æµåŠ¨çš„çº¿æ¡è®©æˆ‘æ„Ÿå—åˆ°äº†ç”Ÿå‘½çš„å¾‹åŠ¨ï¼Œä»¿ä½›åœ¨è¯‰è¯´ç€å®‡å®™çš„å¥¥ç§˜ã€‚"
        - "è¿™ä¸ªå›¾æ¡ˆçš„ç²¾å¦™è®¾è®¡è®©æˆ‘æ„Ÿå—åˆ°äº†è®¾è®¡å¸ˆçš„æ— é™åˆ›æ„å’ŒåŒ å¿ƒç‹¬è¿ã€‚"
        
        QUALITY EXAMPLES OF PERSONALIZED, EMOTIONAL CAPTIONS:
        âœ… "è¿™åªå°çŒ«åœ¨é˜³å…‰ä¸‹æ‰“ç›¹çš„æ ·å­å¤ªæ²»æ„ˆäº†ï¼Œè®©æˆ‘å¿ä¸ä½æƒ³è¦æŠ±æŠ±å®ƒã€‚" (This kitten napping in the sunlight is so healing, I can't help but want to hug it.)
        âœ… "è¿™æœµç«ç‘°çš„å¨‡è‰³è®©æˆ‘æƒ³èµ·äº†åˆæ‹çš„ç¾å¥½ï¼Œæ¯ä¸€ç‰‡èŠ±ç“£éƒ½è¯‰è¯´ç€æµªæ¼«çš„æ•…äº‹ã€‚" (This rose's delicate beauty reminds me of the sweetness of first love, every petal tells a romantic story.)
        âœ… "çœ‹ç€è¿™ä½å¨å¸ˆä¸“æ³¨çƒ¹é¥ªçš„æ ·å­ï¼Œæˆ‘ä»¿ä½›é—»åˆ°äº†å®¶çš„å‘³é“ï¼Œå¿ƒä¸­æ¶Œèµ·æ¸©æš–çš„æ„Ÿè§‰ã€‚" (Watching this chef cook with such focus, I can almost smell the taste of home, feeling warmth in my heart.)
        
        BAD EXAMPLES TO AVOID:
        âŒ "è¿™æ˜¯a person with a surprised expression" (Mixed language)
        âŒ "è¿™æ˜¯ä¸€ä¸ªäºº" (Too generic, no emotion)
        âŒ "è¿™æ˜¯ç…§ç‰‡" (Too vague, no personal reaction)
        âŒ "è¿™æ˜¯ä¸œè¥¿" (Meaningless, no specific details)
        âŒ "è¿™å¾ˆå¥½çœ‹" (Too simple, no emotional depth)
        âŒ "è¿™æ˜¯çº¢è‰²çš„" (Too basic, no personal perspective)
        
        PERSONALIZED RESPONSE FORMAT:
        Write your response as natural, flowing text that captures your personal reaction to this image. 
        Include 2-3 different Chinese sentences that express your genuine feelings and observations.
        For each Chinese sentence, provide the pinyin pronunciation and English translation.
        
        Format your response like this:
        
        1. [Your first personal Chinese sentence about the image]
   Pinyin: [pinyin with tone marks]
   English: [your English translation]
   
   2. [Your second personal Chinese sentence about the image]
   Pinyin: [pinyin with tone marks]
   English: [your English translation]
   
   3. [Your third personal Chinese sentence about the image]
   Pinyin: [pinyin with tone marks]
   English: [your English translation]
   
   Write naturally and personally - don't worry about strict formatting. Focus on expressing your genuine emotional response to what you see in this image.`;

        const requestBody = {
            model: 'gpt-4o-mini',
            messages: [
                {
                    role: 'user',
                    content: prompt
                }
            ],
            max_tokens: 800,
            temperature: 0.7, // Increased for more creative and personalized responses
            top_p: 0.9,
            frequency_penalty: 0.3, // Increased to encourage more varied vocabulary
            presence_penalty: 0.2 // Increased to encourage more diverse expressions
        };

        console.log('ğŸ” Making API request for caption generation...');
        console.log('ğŸ“Š Caption generation attempt:', retryCount + 1);
        console.log('ğŸ¯ Analysis data for caption generation:', {
            mainSubject: analysis.mainSubject,
            category: analysis.category,
            keywords: analysis.keywords?.length || 0,
            confidence: analysis.confidence
        });
        
        const data = await makeApiRequestWithFallback(requestBody);
        console.log('âœ… Caption API request successful, processing response...');
        const responseText = data.choices[0].message.content;
        
        console.log('ğŸ“ Caption response length:', responseText.length);
        console.log('ğŸ“ Caption response preview:', responseText.substring(0, 200) + '...');
        
        // Add detailed logging for debugging
        console.log('ğŸ“ Full API response for captions:', JSON.stringify(data, null, 2));
        console.log('ğŸ“ Response text to parse:', responseText);
        
        let result;
        try {
            // Log the raw response for debugging
            console.log('ğŸ” Raw AI caption response:', responseText);
            
            // Parse the natural language response format
            const captions = parseNaturalLanguageResponse(responseText, analysis);
            
            if (captions.length === 0) {
                console.warn('âš ï¸ No captions generated by AI');
                throw new Error('AI failed to generate any captions');
            }
            
            const validatedCaptions = validateCaptions(captions, analysis);
            console.log('âœ… Caption validation completed:', validatedCaptions);
            
            // If validation returns empty array, return empty result
            if (validatedCaptions.length === 0) {
                console.warn('âš ï¸ All captions filtered out, no captions will be generated');
                return [];
            }
            
            return validatedCaptions;
        } catch (parseError) {
            console.error('âŒ Failed to parse AI caption response:', parseError);
            console.error('âŒ Parse error details:', {
                message: parseError.message,
                name: parseError.name,
                stack: parseError.stack
            });
            console.error('âŒ Raw response text:', responseText);
            console.error('âŒ Response text length:', responseText.length);
            
            // Log response structure analysis
            console.log('ğŸ” Response structure analysis:', {
                hasChineseText: /[\u4e00-\u9fff]/.test(responseText),
                hasNumberedItems: /^[0-9]+\./.test(responseText),
                hasPinyinMarkers: /pinyin:|æ‹¼éŸ³:/i.test(responseText),
                hasEnglishMarkers: /english:|è‹±æ–‡:/i.test(responseText)
            });
            
            // Try to extract captions from malformed response
            console.log('ğŸ”„ Attempting to extract captions from malformed response...');
            const extractedCaptions = extractCaptionsFromText(responseText, analysis);
            
            if (extractedCaptions.length > 0) {
                console.log('âœ… Successfully extracted captions from malformed response:', extractedCaptions.length);
                return extractedCaptions;
            }
            
            // If all else fails, return empty result
            console.log('ğŸ”„ All caption generation attempts failed, no captions will be generated');
            return [];
        }

    } catch (error) {
        console.error('Error generating Chinese descriptions:', error);
        
        // Retry logic for caption generation failures
        if (retryCount < maxRetries && (
            error.message.includes('AI failed to generate any captions') ||
            error.message.includes('Failed to parse AI caption response')
        )) {
            console.log(`ğŸ”„ Retrying caption generation (attempt ${retryCount + 1}/${maxRetries})...`);
            await new Promise(resolve => setTimeout(resolve, 1000)); // Wait 1 second before retry
            return generateChineseDescriptions(analysis, retryCount + 1);
        }
        
        // If all retries failed, return empty result
        console.log('ğŸ”„ All caption generation attempts failed, no captions will be generated...');
        
        // Check if the error is quota-related or API limit related
        if (error.message.includes('quota has been exceeded') || error.message.includes('quota exceeded') || 
            error.message.includes('Insufficient credits') || error.message.includes('credits') ||
            error.message.includes('Temporary API limit') || error.message.includes('API access issue')) {
            console.log('ğŸ’° API limit reached - no captions will be generated');
            return [];
        }
        
        console.log('ğŸ”„ Error occurred during caption generation - no captions will be generated');
        return [];
    }
}

// Dictionary lookup function using OpenAI API
async function lookupChineseWord(word) {
    try {
        console.log(`ğŸ” Looking up Chinese word: ${word}`);
        
        const prompt = `You are a Chinese language expert and dictionary. Please provide comprehensive information for the Chinese character/word: "${word}"

CRITICAL REQUIREMENTS:
1. Provide accurate pinyin pronunciation with tone marks (Ä Ã¡ Ç Ã , Ä“ Ã© Ä› Ã¨, etc.)
2. Give multiple definitions if the word has different meanings
3. Include part of speech for each definition
4. Provide 2-3 example sentences in Chinese for each meaning
5. Include English translations for all examples
6. If the word is not a valid Chinese character/word, indicate this clearly

RESPONSE FORMAT (JSON only, no markdown):
{
    "character": "the input character/word",
    "pinyin": "pinyin with tone marks",
    "definitions": [
        {
            "partOfSpeech": "noun/verb/adjective/etc",
            "meaning": "English definition",
            "examples": ["Chinese example 1", "Chinese example 2", "Chinese example 3"]
        }
    ],
    "isValid": true/false,
    "notes": "any additional notes about the word"
}

If the input is not a valid Chinese character or word, set "isValid" to false and provide appropriate notes.`;

        const requestBody = {
            model: 'gpt-4o-mini',
            messages: [
                {
                    role: 'user',
                    content: prompt
                }
            ],
            max_tokens: 1000,
            temperature: 0.3
        };

        const data = await makeDictionaryRequest(requestBody);
        const responseText = data.choices[0].message.content;
        
        // Clean and parse the JSON response
        let jsonText = responseText.trim();
        
        // Remove any markdown code blocks if present
        if (jsonText.includes('```json')) {
            jsonText = jsonText.split('```json')[1].split('```')[0].trim();
        } else if (jsonText.includes('```')) {
            jsonText = jsonText.split('```')[1].split('```')[0].trim();
        }
        
        // Extract JSON from response
        const jsonStart = jsonText.indexOf('{');
        const jsonEnd = jsonText.lastIndexOf('}');
        if (jsonStart !== -1 && jsonEnd !== -1 && jsonEnd > jsonStart) {
            jsonText = jsonText.substring(jsonStart, jsonEnd + 1);
        }
        
        console.log('ğŸ” Raw OpenAI response:', jsonText);
        
        const result = JSON.parse(jsonText);
        
        // Validate the result
        if (!result.character || !result.pinyin || !Array.isArray(result.definitions)) {
            // If the response doesn't have the expected format, create a fallback response
            console.warn('âš ï¸ Invalid response format, creating fallback response');
            return {
                character: word,
                pinyin: 'unknown',
                definitions: [{
                    partOfSpeech: 'unknown',
                    meaning: 'Unable to find definition for this word. It may not be a valid Chinese character or word.',
                    examples: []
                }],
                isValid: false,
                notes: 'Word not found in dictionary'
            };
        }
        
        console.log('âœ… Successfully looked up word:', result);
        return result;
        
    } catch (error) {
        console.error('Error looking up Chinese word:', error);
        throw new Error(`Dictionary lookup failed: ${error.message}`);
    }
}

// Routes

// Health check
app.get('/health', (req, res) => {
    res.json({ status: 'healthy', timestamp: new Date().toISOString() });
});

// Dictionary lookup endpoint
app.get('/api/dictionary/:word', async (req, res) => {
    try {
        const word = req.params.word;
        console.log(`ğŸ“š Dictionary lookup request for: ${word}`);
        
        if (!word || word.trim().length === 0) {
            return res.status(400).json({ error: 'Word parameter is required' });
        }
        
        const result = await lookupChineseWord(word.trim());
        
        res.json({
            success: true,
            data: result,
            source: 'openai'
        });
        
    } catch (error) {
        console.error('Dictionary lookup error:', error);
        
        res.status(500).json({
            success: false,
            error: 'Dictionary lookup failed',
            message: error.message
        });
    }
});

// Usage statistics
app.get('/api/usage', (req, res) => {
    const today = new Date().toISOString().split('T')[0];
    const todayUsage = usageStats.dailyUsage[today] || { requests: 0, cost: 0 };
    
    const stats = {
        totalRequests: usageStats.totalRequests,
        totalCost: usageStats.totalCost,
        requestsByKey: usageStats.requestsByKey,
        dailyUsage: usageStats.dailyUsage,
        cacheSize: usageStats.imageHashes.size,
        activeApiKeys: OPENAI_API_KEY ? 1 : 0,
        todayRequests: todayUsage.requests,
        todayCost: todayUsage.cost,
        // Quota status based on configuration
        estimatedQuotaStatus: {
            requestsToday: todayUsage.requests,
            costToday: todayUsage.cost,
            // Mode-based limits
            estimatedDailyLimit: UNLIMITED_MODE ? 'unlimited' : 100,
            estimatedCostLimit: UNLIMITED_MODE ? 'unlimited' : 5.0,
            quotaWarning: UNLIMITED_MODE ? false : (todayUsage.requests > 80 || todayUsage.cost > 4.0),
            unlimitedMode: UNLIMITED_MODE
        }
    };
    res.json(stats);
});

// Check API usage endpoint
app.get('/api/check-usage', async (req, res) => {
    try {
        const response = await fetch('https://api.openai.com/v1/usage', {
            headers: {
                'Authorization': `Bearer ${OPENAI_API_KEY}`
            }
        });
        
        const usage = await response.json();
        res.json({
            usage: usage,
            localStats: usageStats,
            tip: 'Using "detail: low" for images reduces cost by ~85%'
        });
    } catch (error) {
        res.json({
            error: 'Could not fetch usage',
            localStats: usageStats
        });
    }
});

// Process image and generate captions (OPTIMIZED VERSION)
app.post('/api/analyze-image', upload.single('image'), async (req, res) => {
    try {
        console.log('ğŸ“ Received request to /api/analyze-image (optimized)');
        
        if (!req.file) {
            return res.status(400).json({ error: 'No image file provided' });
        }

        console.log('ğŸ“¸ Processing image:', req.file.originalname);
        
        // Validate file type before processing
        const allowedTypes = ['image/jpeg', 'image/jpg', 'image/png', 'image/gif', 'image/webp'];
        if (!allowedTypes.includes(req.file.mimetype)) {
            console.log('âŒ Unsupported file type:', req.file.mimetype);
            return res.status(400).json({
                success: false,
                error: 'Unsupported file format',
                message: `File type "${req.file.mimetype}" is not supported. Please use: PNG, JPEG, GIF, or WebP formats.`,
                supportedFormats: ['PNG', 'JPEG', 'GIF', 'WebP'],
                receivedFormat: req.file.mimetype
            });
        }
        
        // Check cache first
        const imageHash = generateImageHash(req.file.buffer);
        const cached = getCachedResult(imageHash);

        if (cached) {
            console.log('ğŸ“¦ Returning cached result, no API call needed');
            return res.json({
                success: true,
                analysis: cached.analysis || {},
                captions: cached.captions || cached,
                cached: true
            });
        }
        
        // Convert to base64
        const base64Image = req.file.buffer.toString('base64');
        
        // Single combined prompt for both analysis and caption generation
        const combinedPrompt = `Analyze this image and create Chinese captions.

Step 1: Describe what you see in the image.
Step 2: Create 3 personalized Chinese sentences about it.

Format your response EXACTLY like this:
ANALYSIS:
Main subject: [what is the main subject]
Description: [brief description]
Category: [type of image]

CAPTION1:
Chinese: [natural Chinese sentence with emotion and detail]
Pinyin: [pinyin with tone marks]
English: [English translation]

CAPTION2:
Chinese: [different Chinese sentence]
Pinyin: [pinyin with tone marks]
English: [English translation]

CAPTION3:
Chinese: [another Chinese sentence]
Pinyin: [pinyin with tone marks]
English: [English translation]

Requirements:
- Chinese sentences must be natural, emotional, and specific to this image
- Use ONLY Chinese characters in the Chinese field (no English mixed in)
- Include proper Chinese punctuation (ã€‚ï¼ï¼Ÿ)
- Make each sentence 10-30 characters long
- Express personal feelings or observations about the image`;

        // Make a SINGLE API call
        console.log('ğŸš€ Making single optimized API call...');
        const response = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: {
                'Authorization': `Bearer ${OPENAI_API_KEY}`,
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({
                model: 'gpt-4o-mini',
                messages: [{
                    role: 'user',
                    content: [
                        { type: 'text', text: combinedPrompt },
                        { 
                            type: 'image_url', 
                            image_url: { 
                                url: `data:${req.file.mimetype};base64,${base64Image}`,
                                detail: 'low'  // Use 'low' to reduce token usage
                            } 
                        }
                    ]
                }],
                max_tokens: 500,
                temperature: 0.7
            })
        });

        if (!response.ok) {
            const errorData = await response.json();
            console.error('API Error:', errorData);
            
            // Check for quota errors
            if (response.status === 429 || errorData.error?.type === 'insufficient_quota' || 
                errorData.error?.code === 'insufficient_quota' || 
                errorData.error?.message?.includes('quota')) {
                console.log('ğŸ’° Quota exceeded, returning fallback response');
                
                // Cache the fallback result
                cacheResult(imageHash, { 
                    analysis: {
                        mainSubject: 'image content',
                        description: 'Image analysis temporarily unavailable due to API quota limits',
                        category: 'general'
                    },
                    captions: [{
                        chinese: 'è¿™æ˜¯ä¸€å¼ æœ‰è¶£çš„å›¾ç‰‡ã€‚',
                        pinyin: 'zhÃ¨ shÃ¬ yÄ« zhÄng yÇ’u qÃ¹ de tÃº piÃ n',
                        english: 'This is an interesting image.',
                        relevance: 'medium'
                    }]
                });
                
                return res.json({
                    success: true,
                    analysis: {
                        mainSubject: 'image content',
                        description: 'Image analysis temporarily unavailable due to API quota limits',
                        category: 'general'
                    },
                    captions: [{
                        chinese: 'è¿™æ˜¯ä¸€å¼ æœ‰è¶£çš„å›¾ç‰‡ã€‚',
                        pinyin: 'zhÃ¨ shÃ¬ yÄ« zhÄng yÇ’u qÃ¹ de tÃº piÃ n',
                        english: 'This is an interesting image.',
                        relevance: 'medium'
                    }],
                    quotaExceeded: true,
                    message: 'API quota exceeded - using fallback captions'
                });
            }
            throw new Error(`API request failed: ${errorData.error?.message || 'Unknown error'}`);
        }

        const data = await response.json();
        const responseText = data.choices[0].message.content;
        console.log('âœ… Received response, parsing...');

        // Parse the structured response
        const analysis = {};
        const captions = [];

        // Extract analysis
        const analysisMatch = responseText.match(/ANALYSIS:([\s\S]*?)(?=CAPTION1:|$)/);
        if (analysisMatch) {
            const analysisText = analysisMatch[1];
            const subjectMatch = analysisText.match(/Main subject:\s*(.+)/i);
            const descMatch = analysisText.match(/Description:\s*(.+)/i);
            const categoryMatch = analysisText.match(/Category:\s*(.+)/i);
            
            analysis.mainSubject = subjectMatch ? subjectMatch[1].trim() : 'image content';
            analysis.description = descMatch ? descMatch[1].trim() : 'Image description';
            analysis.category = categoryMatch ? categoryMatch[1].trim() : 'general';
        }

        // Extract captions
        for (let i = 1; i <= 3; i++) {
            const captionPattern = new RegExp(`CAPTION${i}:([\\s\\S]*?)(?=CAPTION${i+1}:|$)`, 'i');
            const captionMatch = responseText.match(captionPattern);
            
            if (captionMatch) {
                const captionText = captionMatch[1];
                const chineseMatch = captionText.match(/Chinese:\s*(.+)/i);
                const pinyinMatch = captionText.match(/Pinyin:\s*(.+)/i);
                const englishMatch = captionText.match(/English:\s*(.+)/i);
                
                if (chineseMatch && chineseMatch[1].trim()) {
                    captions.push({
                        chinese: chineseMatch[1].trim(),
                        pinyin: pinyinMatch ? pinyinMatch[1].trim() : 'pÄ«n yÄ«n',
                        english: englishMatch ? englishMatch[1].trim() : 'Translation',
                        relevance: 'high'
                    });
                }
            }
        }

        // If parsing failed, create fallback
        if (captions.length === 0) {
            console.log('âš ï¸ No captions parsed, using comprehensive fallback');
            const fallbackCaptions = generateFallbackCaptions(req.file.buffer, req.file.mimetype);
            captions.push(...fallbackCaptions);
        }

        console.log(`âœ… Successfully generated ${captions.length} captions`);

        // Cache the result
        cacheResult(imageHash, { analysis, captions });

        // Update usage stats
        usageStats.totalRequests++;
        saveUsageStats();

        res.json({
            success: true,
            analysis: analysis,
            captions: captions
        });

    } catch (error) {
        console.error('Error in analyze-image:', error);
        
        // Always provide fallback captions instead of failing
        console.log('ğŸ”„ Error occurred, providing fallback captions');
        
        const fallbackAnalysis = generateFallbackAnalysis();
        const fallbackCaptions = generateFallbackCaptions(req.file?.buffer || Buffer.from('fallback'), req.file?.mimetype || 'image/jpeg');
        
        res.json({
            success: true,
            analysis: fallbackAnalysis,
            captions: fallbackCaptions,
            fallbackUsed: true,
            message: 'Using fallback captions due to API issues',
            error: error.message
        });
    }
});

// Rate caption endpoint
app.post('/api/rate-caption', (req, res) => {
    try {
        const { captionId, rating, feedback } = req.body;
        
        // Store rating (in a real app, you'd save to a database)
        console.log(`ğŸ“Š Caption rating: ${rating}/5 for caption ${captionId}`);
        if (feedback) {
            console.log(`ğŸ’¬ Feedback: ${feedback}`);
        }
        
        res.json({ success: true, message: 'Rating recorded' });
    } catch (error) {
        console.error('Error recording rating:', error);
        res.status(500).json({ error: 'Failed to record rating' });
    }
});

// Clear cache endpoint
app.post('/api/clear-cache', (req, res) => {
    try {
        usageStats.imageHashes.clear();
        saveUsageStats();
        res.json({ success: true, message: 'Cache cleared' });
    } catch (error) {
        console.error('Error clearing cache:', error);
        res.status(500).json({ error: 'Failed to clear cache' });
    }
});

// Test API connectivity endpoint
app.get('/api/test', async (req, res) => {
    try {
        console.log('ğŸ§ª Testing API connectivity...');
        
        const testRequest = {
            model: 'gpt-4o-mini',
            messages: [
                {
                    role: 'user',
                    content: 'Say "API is working"'
                }
            ],
            max_tokens: 10
        };
        
        const result = await makeApiRequestWithFallback(testRequest, 1);
        
        res.json({
            success: true,
            message: 'API connection successful',
            response: result.choices[0].message.content
        });
    } catch (error) {
        res.status(500).json({
            success: false,
            message: 'API connection failed',
            error: error.message
        });
    }
});

// Simple API test endpoint for debugging
app.get('/api/test-simple', async (req, res) => {
    try {
        console.log('ğŸ§ª Testing simple API connection...');
        
        const response = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: {
                'Authorization': `Bearer ${OPENAI_API_KEY}`,
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({
                model: 'gpt-4o-mini',
                messages: [{ role: 'user', content: 'Say "Hello"' }],
                max_tokens: 10
            })
        });
        
        const data = await response.json();
        res.json({ 
            success: response.ok, 
            status: response.status,
            data: data 
        });
    } catch (error) {
        res.json({ 
            success: false, 
            error: error.message 
        });
    }
});

// MINIMAL TEST ENDPOINT - Bypasses all complex logic
app.post('/api/test-minimal', upload.single('image'), async (req, res) => {
    console.log('ğŸ”´ MINIMAL TEST STARTED');
    
    try {
        // Test 1: Check if we have an API key
        if (!OPENAI_API_KEY) {
            return res.json({ error: 'No API key found', check: 'Check your .env file' });
        }
        
        console.log('âœ… API Key exists:', OPENAI_API_KEY.substring(0, 10) + '...');
        
        // Test 2: Simple text-only API call
        const testResponse = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: {
                'Authorization': `Bearer ${OPENAI_API_KEY}`,
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({
                model: 'gpt-3.5-turbo',  // Use cheaper model for testing
                messages: [{ role: 'user', content: 'Say "API works"' }],
                max_tokens: 10
            })
        });
        
        const testData = await testResponse.json();
        console.log('ğŸ“¡ API Response Status:', testResponse.status);
        console.log('ğŸ“¡ API Response:', JSON.stringify(testData));
        
        if (!testResponse.ok) {
            return res.json({
                error: 'API call failed',
                status: testResponse.status,
                details: testData
            });
        }
        
        // Test 3: If image provided, test image analysis with minimal tokens
        if (req.file) {
            console.log('ğŸ–¼ï¸ Testing with image...');
            const base64Image = req.file.buffer.toString('base64');
            
            const imageResponse = await fetch('https://api.openai.com/v1/chat/completions', {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${OPENAI_API_KEY}`,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    model: 'gpt-4o-mini',
                    messages: [{
                        role: 'user',
                        content: [
                            { type: 'text', text: 'Say what you see in 3 words only' },
                            { 
                                type: 'image_url', 
                                image_url: { 
                                    url: `data:image/jpeg;base64,${base64Image}`,
                                    detail: 'low'
                                } 
                            }
                        ]
                    }],
                    max_tokens: 20
                })
            });
            
            const imageData = await imageResponse.json();
            console.log('ğŸ–¼ï¸ Image API Response:', JSON.stringify(imageData));
            
            return res.json({
                success: true,
                textTest: testData.choices?.[0]?.message?.content || 'No response',
                imageTest: imageData.choices?.[0]?.message?.content || 'No response',
                imageStatus: imageResponse.status,
                imageError: imageData.error
            });
        }
        
        return res.json({
            success: true,
            message: testData.choices?.[0]?.message?.content || 'No response'
        });
        
    } catch (error) {
        console.error('ğŸ”´ MINIMAL TEST ERROR:', error);
        return res.json({
            error: 'Exception occurred',
            message: error.message,
            type: error.constructor.name
        });
    }
});

// Configuration check endpoint
app.get('/api/check-config', (req, res) => {
    res.json({
        hasApiKey: !!OPENAI_API_KEY,
        keyPrefix: OPENAI_API_KEY ? OPENAI_API_KEY.substring(0, 7) : 'none',
        keyLength: OPENAI_API_KEY ? OPENAI_API_KEY.length : 0,
        hasBackupCaptionKey: !!BACKUP_CAPTION_API_KEY,
        backupCaptionKeyPrefix: BACKUP_CAPTION_API_KEY ? BACKUP_CAPTION_API_KEY.substring(0, 7) : 'none',
        backupCaptionKeyCompatible: isOpenAICompatible(BACKUP_CAPTION_API_KEY),
        hasBackupDictionaryKey: !!BACKUP_DICTIONARY_API_KEY,
        backupDictionaryKeyPrefix: BACKUP_DICTIONARY_API_KEY ? BACKUP_DICTIONARY_API_KEY.substring(0, 7) : 'none',
        backupDictionaryKeyCompatible: isOpenAICompatible(BACKUP_DICTIONARY_API_KEY),
        nodeEnv: process.env.NODE_ENV,
        unlimitedMode: UNLIMITED_MODE,
        aggressiveFallback: AGGRESSIVE_FALLBACK
    });
});

// Quota status endpoint
app.get('/api/quota-status', async (req, res) => {
    try {
        // Test a simple API call to check quota status
        const testResponse = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: {
                'Authorization': `Bearer ${OPENAI_API_KEY}`,
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({
                model: 'gpt-3.5-turbo',
                messages: [{ role: 'user', content: 'test' }],
                max_tokens: 1
            })
        });
        
        const testData = await testResponse.json();
        
        res.json({
            quotaStatus: testResponse.ok ? 'available' : 'exceeded',
            status: testResponse.status,
            error: testData.error,
            localStats: usageStats,
            recommendation: testResponse.ok ? 
                'API quota is available' : 
                'API quota exceeded - using fallback captions'
        });
    } catch (error) {
        res.json({
            quotaStatus: 'error',
            error: error.message,
            localStats: usageStats,
            recommendation: 'Unable to check quota status'
        });
    }
});

// Test fallback system endpoint
app.get('/api/test-fallback', (req, res) => {
    try {
        console.log('ğŸ§ª Testing fallback system...');
        
        // Create a dummy image buffer for testing
        const testBuffer = Buffer.from('test-image-data');
        
        const fallbackAnalysis = generateFallbackAnalysis();
        const fallbackCaptions = generateFallbackCaptions(testBuffer, 'image/jpeg');
        
        res.json({
            success: true,
            message: 'Fallback system test successful',
            analysis: fallbackAnalysis,
            captions: fallbackCaptions,
            fallbackUsed: true,
            timestamp: new Date().toISOString()
        });
    } catch (error) {
        res.json({
            success: false,
            error: error.message,
            timestamp: new Date().toISOString()
        });
    }
});

// Debug endpoint to test image processing
app.post('/api/debug-image', upload.single('image'), async (req, res) => {
    try {
        console.log('ğŸ” DEBUG: Image upload received');
        console.log('ğŸ” DEBUG: File info:', {
            originalname: req.file?.originalname,
            mimetype: req.file?.mimetype,
            size: req.file?.size
        });
        
        if (!req.file) {
            return res.json({ error: 'No file uploaded' });
        }
        
        // Test file type validation
        const allowedTypes = ['image/jpeg', 'image/jpg', 'image/png', 'image/gif', 'image/webp'];
        const isValidType = allowedTypes.includes(req.file.mimetype);
        
        // Test API call
        let apiTestResult = null;
        try {
            const base64Image = req.file.buffer.toString('base64');
            const response = await fetch('https://api.openai.com/v1/chat/completions', {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${OPENAI_API_KEY}`,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    model: 'gpt-4o-mini',
                    messages: [{
                        role: 'user',
                        content: [
                            { type: 'text', text: 'Say "test successful"' },
                            { 
                                type: 'image_url', 
                                image_url: { 
                                    url: `data:${req.file.mimetype};base64,${base64Image}`,
                                    detail: 'low'
                                } 
                            }
                        ]
                    }],
                    max_tokens: 10
                })
            });
            
            const data = await response.json();
            apiTestResult = {
                success: response.ok,
                status: response.status,
                error: data.error,
                response: data.choices?.[0]?.message?.content
            };
        } catch (apiError) {
            apiTestResult = {
                success: false,
                error: apiError.message
            };
        }
        
        res.json({
            fileValidation: {
                isValidType,
                mimetype: req.file.mimetype,
                size: req.file.size,
                originalname: req.file.originalname
            },
            apiTest: apiTestResult,
            timestamp: new Date().toISOString()
        });
        
    } catch (error) {
        res.json({
            error: error.message,
            timestamp: new Date().toISOString()
        });
    }
});

// Serve index.html for root route FIRST
app.get('/', (req, res) => {
    res.sendFile(path.join(__dirname, 'index.html'));
});

// Serve static files (but exclude certain files)
app.use(express.static('.', {
    index: false, // Disable directory listing
    setHeaders: (res, path) => {
        // Exclude certain files from being served
        if (path.endsWith('.sh') || path.endsWith('.env') || path.endsWith('.json')) {
            res.setHeader('Content-Type', 'text/plain');
        }
    }
}));

// Start server
app.listen(PORT, () => {
    console.log(`Server running on http://localhost:${PORT}`);
    console.log(`Usage tracking enabled`);
    console.log(`Caching enabled`);
    console.log(` API keys secured on backend`);
    console.log(`Active API keys: ${OPENAI_API_KEY ? 1 : 0}`);
    console.log(`Backup caption key: ${BACKUP_CAPTION_API_KEY ? 'ENABLED' : 'DISABLED'}`);
    console.log(`Backup dictionary key: ${BACKUP_DICTIONARY_API_KEY ? 'ENABLED' : 'DISABLED'}`);
    console.log(`Unlimited mode: ${UNLIMITED_MODE ? 'ENABLED' : 'DISABLED'}`);
    console.log(`Aggressive fallback: ${AGGRESSIVE_FALLBACK ? 'ENABLED' : 'DISABLED'}`);
    if (UNLIMITED_MODE) {
        console.log(`Enhanced fallback system active for seamless experience`);
    }
    if (AGGRESSIVE_FALLBACK) {
        console.log(`Aggressive fallback mode - bypassing API calls for maximum reliability`);
    }
});

// Graceful shutdown
process.on('SIGINT', () => {
    console.log('\nShutting down server...');
    saveUsageStats();
    process.exit(0);
});
